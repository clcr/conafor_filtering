{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from dbfread import DBF\n",
    "import numpy as np\n",
    "import shutil\n",
    "import tpot\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_dbf_as_frame(dbf_path, encoding = \"UTF-8\"):\n",
    "    \"\"\"Opens a DBF as a pandas dataframe\"\"\"\n",
    "    dbf = DBF(dbf_path, encoding)\n",
    "    return pandas.DataFrame(iter(dbf))\n",
    "\n",
    "\n",
    "def find_changes(change_directory):\n",
    "    \"\"\"Returns a list of dbf files that contain changes\"\"\"\n",
    "    out = []\n",
    "    with os.scandir(change_directory) as it:\n",
    "        for file in it:\n",
    "            if file.endswith(\".dbf\"):\n",
    "                if check_for_real_change(file):\n",
    "                    out.append(file)\n",
    "\n",
    "\n",
    "def check_for_real_change(dbf_path):\n",
    "    frame = open_dbf_as_frame(dbf_path)\n",
    "\n",
    "\n",
    "def normalise_column(dataframe, column, min_val=0, max_val=1):\n",
    "    floats = dataframe[column].values.astype(float)\n",
    "    scaler = preprocessing.MinMaxScalar()\n",
    "    scaled = scalar.fit_transform(floats)\n",
    "    dataframe.loc[:,column] = scaled\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes_frame = open_dbf_as_frame(r\"D:\\conafor\\changes\\changes.dbf\")\n",
    "#false_frame =pandas.DataFrame([open_dbf_as_frame(frame) for frame in glob(r\"D:\\CONAFOR\\false changes\\*.dbf\")])\n",
    "false_frame = open_dbf_as_frame(r\"D:\\CONAFOR\\false changes\\Jal_LCC_IRE_LANDSAT2014_2016_PARTE2.dbf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -4.915037\n",
       "1      -2.152306\n",
       "2      -0.762475\n",
       "3      -6.188069\n",
       "4      -5.330953\n",
       "5       5.247676\n",
       "6       0.754436\n",
       "7      -2.944607\n",
       "8       2.959903\n",
       "9       4.276427\n",
       "10      7.535928\n",
       "11     -3.617070\n",
       "12     -1.740002\n",
       "13      0.014006\n",
       "14     -1.561229\n",
       "15      3.258401\n",
       "16     -0.538015\n",
       "17      0.336020\n",
       "18      0.575550\n",
       "19     -0.278190\n",
       "20      1.623141\n",
       "21      0.493700\n",
       "22     -4.199460\n",
       "23     -0.958318\n",
       "24      0.311273\n",
       "25     -0.161764\n",
       "26      0.036454\n",
       "27     -0.413286\n",
       "28      0.264839\n",
       "29      0.242770\n",
       "          ...   \n",
       "5574   -0.511274\n",
       "5575   -2.548631\n",
       "5576   -1.752843\n",
       "5577   -1.131555\n",
       "5578   -2.196405\n",
       "5579   -1.572842\n",
       "5580   -0.905038\n",
       "5581   -0.525744\n",
       "5582   -0.733409\n",
       "5583   -1.757665\n",
       "5584   -1.060178\n",
       "5585   -1.328657\n",
       "5586   -0.809264\n",
       "5587   -0.618995\n",
       "5588   -0.361330\n",
       "5589   -1.362891\n",
       "5590   -0.187874\n",
       "5591   -0.333082\n",
       "5592   -0.734261\n",
       "5593   -0.469655\n",
       "5594   -1.766482\n",
       "5595   -0.952193\n",
       "5596    1.481912\n",
       "5597    0.302044\n",
       "5598   -1.781410\n",
       "5599   -2.109811\n",
       "5600   -0.664127\n",
       "5601   -0.873930\n",
       "5602    2.485211\n",
       "5603    0.226554\n",
       "Name: maf_2, Length: 5604, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = \"maf_2\"\n",
    "changes_frame[foo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Join_Count', u'TARGET_FID', u'OBJECTID_1', u'FID_LCC_IR', u'oid_1',\n",
       "       u'change', u'mdmx_t1', u'mdmx_t2', u'mdmx_t1t2', u'mdmx_cls',\n",
       "       u'ipcc_dyna', u'mdmx_t1_l', u'prob_cmb', u'maf_4', u'maf_5', u'maf_6',\n",
       "       u'maf_1', u'maf_2', u'maf_3', u'tcd_t2', u'tcd_t1', u'met_t1_1',\n",
       "       u'met_t1_3', u'met_t1_2', u'met_t1_5', u'met_t1_4', u'met_t1_7',\n",
       "       u'met_t1_6', u'met_t2_6', u'met_t2_7', u'met_t2_4', u'met_t2_5',\n",
       "       u'met_t2_2', u'met_t2_3', u'met_t2_1', u'area', u'id', u'DNDVIT2_T1',\n",
       "       u'Val_Cambio', u'Shape_Leng', u'Shape_Area', u'MASC', u'interprete',\n",
       "       u'metodo', u'Val_T1', u'Val_T2', u'Join_Cou_1', u'TARGET_F_1',\n",
       "       u'LC_16'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_frame.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_columns = [u'tcd_t1', u'met_t1_1',\n",
    "                   u'met_t1_3', u'met_t1_2', u'met_t1_5', u'met_t1_4', u'met_t1_7',\n",
    "                   u'met_t1_6', u'met_t2_6', u'met_t2_7', u'met_t2_4', u'met_t2_5',\n",
    "                   u'met_t2_2', u'met_t2_3', u'met_t2_1', u'Shape_Area', 'DNDVIT2_T1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_features = changes_frame.filter(items=feature_columns).sample(2000).values\n",
    "false_features = changes_frame.filter(items=feature_columns).sample(2000).values\n",
    "features = np.concatenate([change_features, false_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'MinMaxScalar'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-6ba0de8fc058>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnormalise_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchanges_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'met_t1_1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-30-7ce6dc15cf4c>\u001b[0m in \u001b[0;36mnormalise_column\u001b[1;34m(dataframe, column, min_val, max_val)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mnormalise_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mfloats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMinMaxScalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mscaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscalar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'module' object has no attribute 'MinMaxScalar'"
     ]
    }
   ],
   "source": [
    "normalise_column(changes_frame, 'met_t1_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = np.concatenate(\n",
    "    [np.ones(len(change_features)), np.zeros(len(false_features))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000L,)\n",
      "(4000L, 18L)\n"
     ]
    }
   ],
   "source": [
    "print(classes.shape)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features, test_features, train_classes, test_classes = train_test_split(features, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 0., 0., 1.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: xgboost.XGBClassifier is not available and will not be used by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b715ab496e304009ba631ebd22ee0b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SEJveChjaGlsZHJlbj0oSW50UHJvZ3Jlc3ModmFsdWU9MCwgZGVzY3JpcHRpb249dSdPcHRpbWl6YXRpb24gUHJvZ3Jlc3MnLCBtYXg9NTAxMDAsIHN0eWxlPVByb2dyZXNzU3R5bGUoZGVzY3LigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.514342241691\n",
      "Generation 2 - Current best internal CV score: 0.514342241691\n",
      "Generation 3 - Current best internal CV score: 0.514342241691\n",
      "Generation 4 - Current best internal CV score: 0.516328357394\n",
      "Generation 5 - Current best internal CV score: 0.516996695361\n",
      "Generation 6 - Current best internal CV score: 0.516996695361\n",
      "Generation 7 - Current best internal CV score: 0.516996695361\n",
      "Generation 8 - Current best internal CV score: 0.516996695361\n",
      "Generation 9 - Current best internal CV score: 0.517000588891\n",
      "Generation 10 - Current best internal CV score: 0.519342814841\n",
      "Generation 11 - Current best internal CV score: 0.519342814841\n",
      "Generation 12 - Current best internal CV score: 0.519342814841\n",
      "\n",
      "\n",
      "TPOT closed during evaluation in one generation.\n",
      "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
      "\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "\n",
      "Best pipeline: LogisticRegression(RFE(LogisticRegression(input_matrix, C=0.01, dual=False, penalty=l2), criterion=gini, max_features=0.9500000000000001, n_estimators=100, step=0.6500000000000001), C=0.01, dual=False, penalty=l2)\n"
     ]
    }
   ],
   "source": [
    "optimiser = tpot.TPOTClassifier(generations = 500, population_size = 100, n_jobs=-1, cv=5, verbosity=2, warm_start=True)\n",
    "optimiser.fit(train_features, train_classes)\n",
    "optimiser.export(\"conafor_tpot_v7.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-aafefdcb89d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"conafor_tpot_v1.py\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mout_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtrue_detections\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout_classes\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtest_classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue_detections\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue_detections\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "optimiser.export(\"conafor_tpot_v7.py\")\n",
    "out_classes = model.predict(test_features)\n",
    "true_detections = out_classes == test_classes\n",
    "print(np.count_nonzero(true_detections)/float(len(true_detections)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.count_nonzero(true_detections)/float(len(true_detections))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (tpot)",
   "language": "python",
   "name": "tpot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
